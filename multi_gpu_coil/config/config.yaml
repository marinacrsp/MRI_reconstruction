seed: 7
### 3 gpus
runtype: train
# runtype: test

path_to_outputs: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_02_06_train
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_12_26/2025-01-05_09h03m47s/checkpoints/epoch_0199.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_12_26/2025-01-05_15h58m52s/checkpoints/epoch_0099.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-10_12h53m35s/checkpoints/epoch_0149.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-11_10h40m22s/checkpoints/epoch_0149.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-13_13h13m43s/checkpoints/epoch_0199.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-13_13h11m35s/checkpoints/epoch_0199.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-14_18h48m12s/checkpoints/epoch_0199.pt # 1024 dimension
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_01_10_train/2025-01-14_18h49m51s/checkpoints/epoch_0199.pt
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_02_06_train/2025-02-21_09h40m45s/checkpoints/epoch_0199.pt # trained 200 epochs, regularization on 1024, 512 embedds
model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_02_06_train/2025-02-21_11h29m51s/checkpoints/epoch_0199.pt

# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_12_26/2025-01-08_07h23m42s/checkpoints/epoch_0099.pt # 30 volumes
# model_checkpoint: /scratch_net/ken/mcrespo/proj_marina/logs_new/multivol_12_26/2025-01-08_22h13m56s/checkpoints/epoch_0099.pt
dataset:
  path_to_data: /itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/
  n_volumes: 15
  n_slices: 2
  with_mask: False  # NOTE: During inference phase, set to True.
  mask_type: Equis
  acceleration: 4
  center_frac: 0.15
  vol_id0: 0

dataloader:
  # effective_batch_size: 1_200_000
  # effective_batch_size: 600_000
  # effective_batch_size: 540_000
  effective_batch_size: 480_000
  # effective_batch_size: 960_000
model:
  id: Siren
  params:
    coord_dim: 3
    vol_embedding_dim: 512
    coil_embedding_dim: 256
    hidden_dim: 512
    L : 10
    n_layers: 8

loss:
  id: MSEL2
  params:
    gamma: 0.01
    sigma: 0.1

optimizer:
  id: Adam
  params:
    lr: 5.e-6 # The dot is necessary, otherwise the parser will mistake this for a string (and not a float).

scheduler:
  id: StepLR
  params:
    gamma: 1.0
    step_size: 20_000

# Training Process
n_epochs: 200
log_interval: 50
checkpoint_interval: 200  # Keep in mind that each checkpoint takes ~241 MB of space.

freeze_model: False

meta_learning:
  epsilon: 1

###################################################
# INFORMATION ONLY - NO EFFECT ON RUN
###################################################
# The following section is for documentation purposes only.
# It does not affect the actual behavior of the run.
# These values are used solely for Tensorboard output, to help identify run types.
hparam_info:
  embedding_vol: 512
  embedding_coil : 256
  dropout: false